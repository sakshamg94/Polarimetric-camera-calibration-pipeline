{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from tqdm import tqdm\n",
    "from mpl_toolkits import mplot3d\n",
    "from klepto.archives import dir_archive\n",
    "import cv2\n",
    "import time\n",
    "import itertools\n",
    "from scipy.io import savemat\n",
    "import gc # to force remove objects' associated memory you deallocate using <<del var_name>>  or <<var_name = None>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEDFORMS = ['corals', 'canopy', 'rocks', 'dunes']\n",
    "flow_speeds = ['fast', 'med', 'slow']\n",
    "submergences = ['Deep', 'Intermed', 'Shallow']\n",
    "colors = {'corals':'dodgerblue','canopy':'green', 'rocks':'orange', 'dunes':'brown'}\n",
    "quantities = ['slope_Azi_angle', 'slope_x', 'slope_y'] # to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bed_idx = 3\n",
    "# flow_idx = 2\n",
    "# submergence_idx = 2\n",
    "TEST = 4\n",
    "DIST = 172\n",
    "BATCH_FRAMES =  75# for data acquired at 3 fp, total of 900, per subfolder 225 frames. 225/75 = 9\n",
    "\n",
    "# # SET the data variables\n",
    "# FLOW_SPEED = flow_speeds[flow_idx]\n",
    "# SUBMERGENCE = submergences[submergence_idx]\n",
    "# BEDFORM = BEDFORMS[bed_idx]\n",
    "# print(\"{}_{}Flow_{}H_test{}\".format(BEDFORM, FLOW_SPEED, SUBMERGENCE, TEST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSD using 2D FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------*****corals_fastFlow_ShallowH****----------------------\n",
      "--------------QUANTITY0: slope_Azi_angle---------\n",
      "#####PORTION: 1#####\n",
      "boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet_subFolder1\n",
      "save folder location created.\n",
      "time taken to process 1 subfolder of data  =  59.21773934364319\n",
      "#####PORTION: 2#####\n",
      "boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet_subFolder2\n",
      "time taken to process 1 subfolder of data  =  57.618881940841675\n",
      "#####PORTION: 3#####\n",
      "boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet_subFolder3\n",
      "time taken to process 1 subfolder of data  =  60.40575814247131\n",
      "#####PORTION: 4#####\n",
      "boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet_subFolder4\n",
      "time taken to process 1 subfolder of data  =  59.337138175964355\n",
      "--------------QUANTITY1: slope_x---------\n",
      "#####PORTION: 1#####\n",
      "boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet_subFolder1\n",
      "time taken to process 1 subfolder of data  =  52.203938722610474\n",
      "#####PORTION: 2#####\n",
      "boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet_subFolder2\n",
      "time taken to process 1 subfolder of data  =  51.35375428199768\n",
      "#####PORTION: 3#####\n",
      "boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet_subFolder3\n",
      "time taken to process 1 subfolder of data  =  54.17670249938965\n",
      "#####PORTION: 4#####\n",
      "boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet_subFolder4\n",
      "time taken to process 1 subfolder of data  =  53.03653025627136\n",
      "--------------QUANTITY2: slope_y---------\n",
      "#####PORTION: 1#####\n",
      "boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet_subFolder1\n",
      "time taken to process 1 subfolder of data  =  52.177568435668945\n",
      "#####PORTION: 2#####\n",
      "boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet_subFolder2\n",
      "time taken to process 1 subfolder of data  =  51.03810000419617\n",
      "#####PORTION: 3#####\n",
      "boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet_subFolder3\n",
      "time taken to process 1 subfolder of data  =  54.07475137710571\n",
      "#####PORTION: 4#####\n",
      "boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet_subFolder4\n",
      "time taken to process 1 subfolder of data  =  52.56316614151001\n"
     ]
    }
   ],
   "source": [
    "s=[np.arange(len(BEDFORMS)), np.arange(len(flow_speeds)), np.arange(len(submergences)) ]\n",
    "for bed_idx,flow_idx,submergence_idx in [(0,0,2)]:#list(itertools.product(*s)): \n",
    "    FLOW_SPEED = flow_speeds[flow_idx]\n",
    "    SUBMERGENCE = submergences[submergence_idx]\n",
    "    BEDFORM = BEDFORMS[bed_idx]\n",
    "    print(\"---------------------*****{}_{}Flow_{}H****----------------------\".format(BEDFORM, FLOW_SPEED, SUBMERGENCE))\n",
    "#     try:\n",
    "    for which_quantity in [0, 1, 2]:\n",
    "        QUANTITY = quantities[which_quantity]\n",
    "        print(\"--------------QUANTITY{}: {}---------\".format(which_quantity,QUANTITY))\n",
    "        for PORTION in [1,2,3,4]: # 4 subfolders split into 4 portions for saving\n",
    "            print(\"#####PORTION: {}#####\".format(PORTION))\n",
    "            accumulated_data = []\n",
    "            for serial,i in enumerate([PORTION]):#range(1,5):\n",
    "                # choose the data\n",
    "                SUBFOLDER = i\n",
    "\n",
    "                # source data folders\n",
    "                data_foldername = \"boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet_subFolder{}\".format(SUBFOLDER)\n",
    "#                 data_foldername = \"{}_{}Flow_{}H_test{}_centeredCam_{}cmDownstreamUpperROI_flume_LookAngle_35Deg_subFolder{}\".format(BEDFORM, FLOW_SPEED, SUBMERGENCE, TEST,DIST, SUBFOLDER)\n",
    "#                     data_foldername = \"{}_{}Flow_{}H_test{}_subFolder{}\".format(BEDFORM, FLOW_SPEED, SUBMERGENCE, TEST, SUBFOLDER)\n",
    "                print(data_foldername)\n",
    "                data_location =  '../TOSHIBA_Drive/saksham_polar_cam_FLIR'\n",
    "#                     save_location =  \"../TOSHIBA_Drive/saksham_polar_cam_FLIR/klepto_bulk_data_saves/all_MATdata_{}_{}Flow_{}H_test{}\".format(BEDFORM, FLOW_SPEED, SUBMERGENCE, TEST)\n",
    "#                 save_location =  \"../TOSHIBA_Drive/saksham_polar_cam_FLIR/klepto_bulk_data_saves/all_MATdata_{}_{}Flow_{}H_test{}_centeredCam_{}cmDownstreamUpperROI/\".format(BEDFORM, FLOW_SPEED, SUBMERGENCE, TEST, DIST)\n",
    "                save_location =  \"../TOSHIBA_Drive/saksham_polar_cam_FLIR/klepto_bulk_data_saves/\" +\\\n",
    "                                    \"all_MATdata_boils_25fps_MedianFilteredRef_25Pump_25cmH_industrialHoseJet/\"\n",
    "                \n",
    "                if not os.path.exists(save_location):\n",
    "                    os.mkdir(save_location)\n",
    "                    print(\"save folder location created.\")\n",
    "                klepto_saved_data_origin = 'klepto_bulk_data_saves' \n",
    "\n",
    "                # retrive the saved data\n",
    "                data_origin = os.path.join(data_location, klepto_saved_data_origin, data_foldername)\n",
    "                bed_data = {BEDFORM:{}}\n",
    "                tic = time.time()\n",
    "                assert os.path.exists(data_origin) == True\n",
    "                data = dir_archive(data_origin, {}, serialized=True, cached=True)\n",
    "                data.load(\"all_sx_maps\", \"all_sy_maps\")\n",
    "\n",
    "                if which_quantity == 0:\n",
    "                    # derive the quantity you want to save -- for preventing OOM error,\n",
    "                    # do the cv2 processing in memory for half the frames, clear memory and repeat once\n",
    "                    NUM_FRAMES = data['all_sy_maps'].shape[-1]\n",
    "\n",
    "                    if which_quantity == 0:\n",
    "                        _, bed_data[BEDFORM]['all_slopeAzi_maps']\\\n",
    "                                    = cv2.cartToPolar(data['all_sy_maps'][:,:,:NUM_FRAMES//2],\\\n",
    "                                                      data['all_sx_maps'][:,:,:NUM_FRAMES//2], \\\n",
    "                                                      angleInDegrees=True)    \n",
    "                        # Accumulate the data-\n",
    "                        accumulated_data.append(bed_data[BEDFORM]['all_slopeAzi_maps'])\n",
    "                        # clear space\n",
    "                        bed_data[BEDFORM]['all_slopeAzi_maps']  = None\n",
    "\n",
    "                        # repeat but notice this time the indices have changed\n",
    "                        _, bed_data[BEDFORM]['all_slopeAzi_maps']\\\n",
    "                                    = cv2.cartToPolar(data['all_sy_maps'][:,:,NUM_FRAMES//2:],\\\n",
    "                                                      data['all_sx_maps'][:,:,NUM_FRAMES//2:], \\\n",
    "                                                      angleInDegrees=True)  \n",
    "                        # Accumulate the data-\n",
    "                        accumulated_data.append(bed_data[BEDFORM]['all_slopeAzi_maps'])\n",
    "                        # clear space\n",
    "                        bed_data[BEDFORM]['all_slopeAzi_maps']  = None\n",
    "                elif which_quantity == 1:\n",
    "                    accumulated_data.append(data['all_sx_maps'])\n",
    "                elif which_quantity == 2:\n",
    "                    accumulated_data.append(data['all_sy_maps'])\n",
    "\n",
    "                toc = time.time()\n",
    "                print(\"time taken to process 1 subfolder of data  = \", toc-tic)\n",
    "\n",
    "                del bed_data, data\n",
    "                gc.collect()\n",
    "\n",
    "            # concatenate all the data so far\n",
    "            data = np.concatenate(accumulated_data, axis =2)\n",
    "            accumulated_data = None\n",
    "\n",
    "            # save the accumulated data\n",
    "#             dic = {QUANTITY:data,\\\n",
    "#                    \"PORTION\":PORTION,\\\n",
    "#                     'BEDFORM':BEDFORM, 'FLOW_SPEED':FLOW_SPEED,'SUBMERGENCE':SUBMERGENCE}\n",
    "            dic = {QUANTITY:data,\\\n",
    "                   \"PORTION\":PORTION}\n",
    "            \n",
    "            # if filenot found error, that could mean the filename is too long!\n",
    "#             filename = '{}_QUANT{}_DIST{}cm_PORTION{}.mat'.format(BEDFORM, QUANTITY, DIST, PORTION)\n",
    "            filename = 'boils_25fps_25Pump_25cmH_QUANTITY_{}_PORTION{}.mat'.format(QUANTITY, PORTION)\n",
    "            save_dest = os.path.join(save_location, filename)\n",
    "            savemat(save_dest,dic)\n",
    "            del dic, data\n",
    "            gc.collect()\n",
    "#     except:\n",
    "#         print(\"got exception for PORTION {}\".format(PORTION))\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
